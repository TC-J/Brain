{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Can't instantiate abstract class WineData without an implementation for abstract methods '__install__', '__preprocess__', 'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 224\u001b[0m\n\u001b[1;32m    220\u001b[0m             zip_file\u001b[38;5;241m.\u001b[39mextractall(data_dir)\n\u001b[1;32m    222\u001b[0m         os\u001b[38;5;241m.\u001b[39mremove(zip_path)\n\u001b[0;32m--> 224\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mWineData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIdentity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwine\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m0.1.0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Can't instantiate abstract class WineData without an implementation for abstract methods '__install__', '__preprocess__', 'dataset'"
     ]
    }
   ],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import Any, Callable, Literal, override, TypeAlias\n",
    "from inspect import signature\n",
    "\n",
    "import torch\n",
    "from brain.util import only_kwargs_from_fn\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from requests import get\n",
    "from pathlib import Path\n",
    "from semver import Version\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "from torch.nn import Module\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from inspect import isclass, isfunction\n",
    "\n",
    "def to_version(version: str | Version):\n",
    "    return version if isinstance(version, Version) else Version.parse(version)\n",
    "\n",
    "\n",
    "class Data(ABC):\n",
    "    \"\"\" \n",
    "        Abstract class that manages the installation, preprocessing, \n",
    "        uninstallation, and the retrieval of the training, and testing\n",
    "        data to be used by the supervisor.\n",
    "\n",
    "        The installation and training-data retrieval-methods must be implemented; the\n",
    "        rest of the functions are overridable - returning None for all but the\n",
    "        uninstall method, which removes the data-dir, by default.\n",
    "\n",
    "        `install` installs the data on the host; if the data is in-memory just\n",
    "        pass/return in the method implementation, or create the data and save it to self for the dataset\n",
    "        functions to fetch it.\n",
    "\n",
    "        `training_data` creates the dataset instance.\n",
    "\n",
    "        `testing_data` returns None, by default; override \n",
    "         it if a testing set should be used by the supervisor.\n",
    "\n",
    "        `uninstall` defaults to deleting the data-dir; override it if their are\n",
    "        side effects like maybe in database cases, or if the data-dir shares\n",
    "        other data that should not be deleted.\n",
    "\n",
    "        `is_installed` is overridable, it defaults to checking to see if the\n",
    "        data-dir is empty.\n",
    "\n",
    "        `__preprocess__` is called after the install method in the constructor, only\n",
    "        if the data is not already installed; it does nothing and is overridable. Use\n",
    "        it for eg extracting zip data and any mutations to the data before the dataset\n",
    "        instance is used to fetch it.\n",
    "\n",
    "        `uninstall` is optionally called by the user after the supervisor runs.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        name: str,\n",
    "        version: str | Version,\n",
    "        data_dir: str | Path | None = None\n",
    "    ):\n",
    "        self.name = name\n",
    "\n",
    "        self.version = to_version(version)\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def install(\n",
    "        self\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "\n",
    "    @override\n",
    "    def __preprocess__(\n",
    "        self\n",
    "    ):\n",
    "        pass\n",
    "\n",
    "\n",
    "    @override\n",
    "    def uninstall(\n",
    "        self\n",
    "    ):\n",
    "        if self.data_dir is not None:\n",
    "            shutil.rmtree(self.data_dir)\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def training_data(\n",
    "        self\n",
    "    ) -> Dataset:\n",
    "        pass\n",
    "\n",
    "\n",
    "    @override\n",
    "    def testing_data(\n",
    "        self\n",
    "    ) -> Dataset | None:\n",
    "        return None\n",
    "\n",
    "\n",
    "    @override\n",
    "    def is_installed(\n",
    "            self\n",
    "    ):\n",
    "        return len(os.listdir(self.data_dir)) > 0\n",
    "\n",
    "Class: TypeAlias = Callable\n",
    "\n",
    "Function: TypeAlias = Callable\n",
    "\n",
    "class Model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        version: str | Version,\n",
    "        module: Module\n",
    "    ):\n",
    "        self.name = name\n",
    "\n",
    "        self.version = to_version(version)\n",
    "\n",
    "        self.module = module\n",
    "\n",
    "class Metrics:\n",
    "    def __init__(\n",
    "        self,\n",
    "        interval: int,\n",
    "        param_norm: bool = False,\n",
    "        grad_norm: bool = False\n",
    "    ):\n",
    "        self.metrics = {}\n",
    "\n",
    "        self.interval = interval\n",
    "\n",
    "        self.has = {\n",
    "            \"param_norm\": param_norm, \n",
    "            \"grad_norm\": grad_norm\n",
    "        }\n",
    "\n",
    "        self.metrics[\"loss_epoch\"] = None\n",
    "\n",
    "        self.metrics[\"loss_interval\"] = None\n",
    "\n",
    "        self.metrics[\"loss_running\"] = None\n",
    "\n",
    "        self.metrics[\"test_loss_epoch\"] = None\n",
    "\n",
    "        self.metrics[\"test_loss_interval\"] = None\n",
    "\n",
    "        self.metrics[\"test_loss_running\"] = None\n",
    "\n",
    "        if param_norm:\n",
    "            self.metrics[\"param_norm_epoch\"] = None\n",
    "\n",
    "            self.metrics[\"param_norm_interval\"] = None\n",
    "\n",
    "            self.metrics[\"param_norm_running\"] = None\n",
    "        \n",
    "        if grad_norm:\n",
    "            self.metrics[\"grad_norm_epoch\"] = None\n",
    "\n",
    "            self.metrics[\"grad_norm_interval\"] = None\n",
    "\n",
    "            self.metrics[\"grad_norm_running\"] = None\n",
    "        \n",
    "\n",
    "        def is_tracking(metric: str):\n",
    "            return self.has[metric]\n",
    "        \n",
    "\n",
    "        def __getitem__(self, key) -> Any:\n",
    "            return self.metrics[key]\n",
    "        \n",
    "\n",
    "        def __setitem__(self, key, value):\n",
    "            self.metrics[key] = value\n",
    "\n",
    "\n",
    "class Brain:\n",
    "    name = None\n",
    "\n",
    "    version = None\n",
    "\n",
    "    model_name = None\n",
    "\n",
    "    model_version = None\n",
    "\n",
    "    data_name = None\n",
    "\n",
    "    data_version = None\n",
    "\n",
    "    supervisor_name = None\n",
    "\n",
    "    supervisor_version = None\n",
    "\n",
    "    metrics = None\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        version: str | Version,\n",
    "        model: Model,\n",
    "    ):\n",
    "        self.name = name\n",
    "\n",
    "        self.version = to_version(version)\n",
    "\n",
    "        self.model = model\n",
    "\n",
    "        self.model_name = model.name\n",
    "\n",
    "        self.model_version = model.version\n",
    "\n",
    "\n",
    "class Supervisor:\n",
    "    \"\"\"\n",
    "        A supervisor is an optimizer and a loss function with\n",
    "        the hyperparameters to construct them.\n",
    "\n",
    "        The supervisor trains a model on a dataset using\n",
    "        a `Data` subclassed instance, an optimizer class, a loss\n",
    "        function or class, and the hyperparameters to construct\n",
    "        the optimizer, the loss (if given as a class), the\n",
    "        data-loaders, as well as the metrics tracking and debugging\n",
    "        options.\n",
    "\n",
    "        The hyperparameters must contain the keyword arguments \n",
    "        in the constructors of the optimizer class, the loss \n",
    "        function class (if it is a class), and the `DataLoader`. \n",
    "        Further metrics tracking and debugging options can be\n",
    "        provided.\n",
    "\n",
    "        Using `supervise` creates a trained model on the datasets\n",
    "        from the `Data` subclass.\n",
    "\n",
    "        So, a supervisor is a snapshot of the optimizer, loss, \n",
    "        and hyperparameters that can train models on data.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            name: str, \n",
    "            version: str | Version,\n",
    "            optimizer: Class,\n",
    "            loss: Class | Function,\n",
    "            **hyperparameters\n",
    "    ):\n",
    "        self.name = name\n",
    "\n",
    "        self.version = to_version(version)\n",
    "\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        self.loss = loss\n",
    "\n",
    "        self.hyperparameters = hyperparameters\n",
    "\n",
    "\n",
    "    def supervise(\n",
    "            self, \n",
    "            name: str,\n",
    "            version: str | Version,\n",
    "            model: Model,\n",
    "            data: Data,\n",
    "            epochs: int\n",
    "    ) -> Brain:\n",
    "        brain = Brain(name, version, model)\n",
    "\n",
    "        brain.supervisor_name = self.name\n",
    "\n",
    "        brain.supervisor_version = self.version\n",
    "\n",
    "        brain.data_name = data.name\n",
    "\n",
    "        brain.data_version = data.version\n",
    "\n",
    "        brain.metrics = Metrics(\n",
    "            **only_kwargs_from_fn(\n",
    "                Metrics.__init__, \n",
    "                self.hyperparameters\n",
    "            )\n",
    "        )\n",
    "\n",
    "        optim = self.optimizer.__init__(\n",
    "            **only_kwargs_from_fn(\n",
    "                self.optimizer.__init__, self.hyperparameters\n",
    "            )\n",
    "        )\n",
    "\n",
    "        loss_fn = self.loss.__init__(\n",
    "            **only_kwargs_from_fn(\n",
    "                self.loss.__init__,\n",
    "                self.hyperparameters\n",
    "            )\n",
    "        ) if isclass(self.loss) else self.loss\n",
    "\n",
    "        training_data = data.training_data()\n",
    "\n",
    "        testing_data = data.testing_data()\n",
    "\n",
    "        has_test = testing_data is not None\n",
    "\n",
    "        train_dl = DataLoader(\n",
    "            dataset=training_data,\n",
    "            **only_kwargs_from_fn(\n",
    "                DataLoader.__init__,\n",
    "                self.hyperparameters\n",
    "            )\n",
    "        )\n",
    "\n",
    "        test_dl = None if testing_data is None else DataLoader(\n",
    "            dataset=testing_data,\n",
    "            **only_kwargs_from_fn(\n",
    "                DataLoader.__init__,\n",
    "                self.hyperparameters\n",
    "            )\n",
    "        )\n",
    "\n",
    "        epoch_losses = []\n",
    "\n",
    "        running_losses = []\n",
    "\n",
    "        interval_losses = []\n",
    "\n",
    "        interval_loss = 0\n",
    "\n",
    "        running_loss = 0\n",
    "\n",
    "        if test_dl is not None:\n",
    "            epoch_test_losses = []\n",
    "\n",
    "            interval_test_losses = []\n",
    "\n",
    "            running_test_losses = []\n",
    "\n",
    "            interval_test_loss = 0\n",
    "\n",
    "            running_test_loss = 0\n",
    "\n",
    "        param_norms_epoch = []\n",
    "\n",
    "        param_norms_interval = []\n",
    "\n",
    "        param_norms_running = []\n",
    "\n",
    "        param_norm_interval = 0\n",
    "        \n",
    "        param_norm_running = 0\n",
    "\n",
    "        grad_norms_epoch = []\n",
    "\n",
    "        grad_norms_interval = []\n",
    "\n",
    "        grad_norms_running = []\n",
    "\n",
    "        grad_norm_interval = 0\n",
    "\n",
    "        grad_norm_running = 0\n",
    "        \n",
    "        nn: Module = brain.model.module\n",
    "\n",
    "        for epoch in epochs:\n",
    "            nn.train(True)\n",
    "\n",
    "            for features_batch, targets_batch in train_dl:\n",
    "                optim.zero_grad()\n",
    "\n",
    "                predictions = nn(features_batch)\n",
    "\n",
    "                loss = loss_fn(predictions, targets_batch)\n",
    "\n",
    "                loss.backward()\n",
    "\n",
    "                optim.step()\n",
    "\n",
    "                loss = loss.item()\n",
    "\n",
    "                interval_loss += loss\n",
    "\n",
    "                running_loss += loss\n",
    "            \n",
    "            # FIXME: all the loss metrics\n",
    "            if (epoch + 1) % brain.metrics.interval == 0:\n",
    "                epoch_losses.append(loss)\n",
    "\n",
    "                interval_losses.append(\n",
    "                    interval_loss / brain.metrics.interval\n",
    "                )\n",
    "\n",
    "                interval_loss = 0\n",
    "\n",
    "                running_losses.append(\n",
    "                    running_loss / epoch\n",
    "                )\n",
    "\n",
    "                print(loss)\n",
    "\n",
    "                # FIXME: parameter norms\n",
    "                if brain.metrics.is_tracking(\"grad_norm\"):\n",
    "                    pass\n",
    "                    \n",
    "                # FIXME: gradient norms\n",
    "                if brain.metrics.is_tracking(\"param_norm\"):\n",
    "                    pass\n",
    "        \n",
    "        if test_dl is not None:\n",
    "            with torch.inference_mode():\n",
    "                nn.eval()\n",
    "\n",
    "                for test_features_batch, test_targets_batch in test_dl:\n",
    "                    test_predictions = nn(test_features_batch)\n",
    "\n",
    "                    test_loss = loss_fn(\n",
    "                        test_predictions,\n",
    "                        test_targets_batch\n",
    "                    ).item()\n",
    "\n",
    "                    interval_test_loss += test_loss\n",
    "\n",
    "                    running_test_loss += test_loss\n",
    "\n",
    "                    # FIXME: all the test metrics\n",
    "                    if (epoch + 1) % brain.metrics.interval == 0:\n",
    "                        epoch_test_losses.append(test_loss.item())\n",
    "\n",
    "                        interval_test_loss = 0\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brain-mUoVbfnf-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
